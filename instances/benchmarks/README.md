# Benchmarks

For this project we have created several benchmarks to test, validate and optimize our implementation on.
The benchmarks range over different sizes, layouts and number of agents to cover a wide spectrum of possible scenarios.
For each benchmark both a native and a "init1" instance can be found. Results to our benchmarks and a conclusion of those 
can be found under '/encodings/idea2/'.

The benchmarks 1-5 are smaller sizes, 6-11 medium sizes and the randomly generated instances are the large instances.


## Benchmark descriptions:

benchmark_01: vertex constrain benchmark 

benchmark_02: vertex constrain benchmark

benchmark_03: 4 2x2 rooms with corridors

benchmark_04: vertex constrain benchmark 2

benchmark_05: 2 3x3 rooms with a corridor

benchmark_06: 2 3x3 rooms with a corridor 

benchmark_07: maze consinsting of 2x2 rooms and corridors 

benchmark_08: shelfs

benchmark_09: bigger rooms connected by one corridor

benchmark_10: bigger rooms connected by one corridor with more robots

benchmark_11: 10 robots on 76 nodes

randomly_generated_instances: contains a few randomly generated instances with different grid sizes and differnt numbers of roboters and shelfs

